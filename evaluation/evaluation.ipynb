{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb41dd6",
   "metadata": {},
   "source": [
    "#### Notes on file structure\n",
    "\n",
    "- results are stored in ../results/results\n",
    "- figures are stored in ../results/figures\n",
    "- folder structure is based on data (i.e. start/end point, number of datapoints and noise level)\n",
    "- file names are based on the actual model i.e. system name, l1 and l2 values \n",
    "- file names are separated by \"_\"\n",
    "- relevant results files are ...\n",
    "    - f\"{filename_addendum}_MLL.pkl\"\n",
    "    - f\"{filename_addendum}_MLL_logs.pkl\"\n",
    "    - f\"{filename_addendum}_MAP.pkl\"\n",
    "    - f\"{filename_addendum}_MAP_logs.pkl\"\n",
    "    - f\"{filename_addendum}_mean_ode_satisfaction_error_MLL.pkl\"\n",
    "    - f\"{filename_addendum}_mean_ode_satisfaction_error_MAP.pkl\"\n",
    "    - f\"{filename_addendum}_sample_ode_satisfaction_error_MLL.pkl\"\n",
    "    - f\"{filename_addendum}_sample_ode_satisfaction_error_MAP.pkl\"\n",
    "    - f\"{filename_addendum}_MLL_model_train_MSEs.pkl\"\n",
    "    - f\"{filename_addendum}_MAP_model_train_MSEs.pkl\"\n",
    "    - f\"{filename_addendum}_MLL_model_test_MSEs.pkl\"\n",
    "    - f\"{filename_addendum}_MAP_model_test_MSEs.pkl\"\n",
    "- relevant figure files are ...\n",
    "    - f\"MLL_model_posterior_{system_name}_l1-{l1_param_val}_l2-{l2_param_val}_{START}-{END}-{COUNT}_{noise_level}.png\"\n",
    "    - f\"MAP_model_posterior_{system_name}_l1-{l1_param_val}_l2-{l2_param_val}_{START}-{END}-{COUNT}_{noise_level}.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f61caa",
   "metadata": {},
   "source": [
    "#### Notes on relevant metrics / summaries / statistics\n",
    "- Visualize the trends for all metrics over increasing training data and noise\n",
    "    - Maybe plot number of datapoints on X and noise level on Y and color the points for MSE/MLL/MAP/... ? (This only works if working with a single model, as we have overlap otherwise)\n",
    "- Display some instances of good/bad trainings for both a lot and few datapoints\n",
    "- Show the difference that we get when we have few datapoints at the start and across the whole domain\n",
    "- Lineplot with different colors for different models, X is number of datapoints, Y is MSE/MLL/MAP/...\n",
    "    - When comparing the ODE satisfaction use a log-scale\n",
    "- Look at some interesting individual cases of the data\n",
    "    - Highlight the slow speed of the moon system in changing its values\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load a specific result from a model\n",
    "def load_model_result(model_name, result_name, results_path=None):\n",
    "    if results_path is None:\n",
    "        results_path = Path.cwd()\n",
    "        results_path = results_path.joinpath('results').joinpath(\"results\")\n",
    "    # Construct the file path based on the model and result names\n",
    "    file_path = results_path.joinpath(f'{model_name}_{result_name}.pkl')\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Result file '{file_path}' does not exist.\")\n",
    "    \n",
    "    # Load the result using dill\n",
    "    with open(file_path, 'rb') as file:\n",
    "        result = dill.load(file)\n",
    "    \n",
    "    return result\n",
    "\n",
    "load_model_result(\"Bipendulum_l1-1.0_l2-2.0\", \"MLL\", results_path=Path.cwd().parent.joinpath(\"results\").joinpath(\"results\").joinpath(\"2-3-1_0.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c876bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model_name(model_name, l1, l2):\n",
    "    \"\"\"\n",
    "    Constructs a model name based on the provided parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): The base name of the model.\n",
    "        l1 (float): The first parameter for the model.\n",
    "        l2 (float): The second parameter for the model.\n",
    "    \n",
    "    Returns:\n",
    "        str: The constructed model name.\n",
    "    \"\"\"\n",
    "    return f\"{model_name}_l1-{l1}_l2-{l2}\"\n",
    "\n",
    "\n",
    "def construct_experiment_name(start, end, count, noise):\n",
    "    return f\"{start}-{end}-{count}_{noise}\"\n",
    "\n",
    "\n",
    "def construct_experiment_path(start, end, count, noise, results_path=None):\n",
    "    \"\"\"\n",
    "    Constructs the path for the experiment results based on the provided parameters.\n",
    "    \n",
    "    Args:\n",
    "        start (float): The start value for the experiment.\n",
    "        end (float): The end value for the experiment.\n",
    "        count (int): The number of samples in the experiment.\n",
    "        noise (float): The noise level in the experiment.\n",
    "        result_path (str, optional): The base path for results. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        str: The constructed path for the experiment results.\n",
    "    \"\"\"\n",
    "    if results_path is None:\n",
    "        results_path = Path.cwd()\n",
    "        results_path = results_path.joinpath('results').joinpath(\"results\")\n",
    "    return results_path.joinpath(f\"{start}-{end}-{count}_{noise}\")\n",
    "\n",
    "\n",
    "print(construct_experiment_path(2, 3, 100, 0.1, results_path=Path.cwd().parent.joinpath(\"results\").joinpath(\"results\")).joinpath(construct_model_name(\"Bipendulum\", 1.0, 2.0)))\n",
    "print(construct_experiment_path(2, 3, 100, 0.1, results_path=Path.cwd().parent.joinpath(\"results\").joinpath(\"results\")).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy Metric Call Dict\n",
    "emcd = {\"MLL\" : \"MLL\",\n",
    "\"MLL logs\": \"MLL_logs\",\n",
    "\"MAP\" : \"MAP\",\n",
    "\"MAP logs\": \"MAP_logs\",\n",
    "\"mean MLL ODE error\": \"mean_ode_satisfaction_error_MLL\",\n",
    "\"mean MAP ODE error\": \"mean_ode_satisfaction_error_MAP\",\n",
    "\"sample MLL ODE error\": \"sample_ode_satisfaction_error_MLL\",\n",
    "\"sample MAP ODE error\": \"sample_ode_satisfaction_error_MAP\",\n",
    "\"MLL train MSEs\": \"MLL_model_train_MSEs\",\n",
    "\"MAP train MSEs\": \"MAP_model_train_MSEs\",\n",
    "\"MLL test MSEs\": \"MLL_model_test_MSEs\",\n",
    "\"MAP test MSEs\": \"MAP_model_test_MSEs\"}\n",
    "\n",
    "# More used as a reference than for actual use\n",
    "all_model_names = [\"Bipendulum\", \"Bipendulum first equation\", \"Bipendulum second equation\", \"Bipendulum Sum eq2 diffed\", \"Bipendulum moon gravitation\", \"Bipendulum Parameterized\", \"No system\"]\n",
    "\n",
    "all_l1_l2_combinations = list([[1.0, 2.0], [1.0, 3.0], [2.0, 3.0]])\n",
    "\n",
    "all_model_settings = list(itertools.chain(itertools.product([\"Bipendulum\", \"Bipendulum first equation\", \"Bipendulum second equation\", \"Bipendulum Sum eq2 diffed\", \"Bipendulum moon gravitation\"], [[1.0, 2.0], [1.0, 3.0], [2.0, 3.0]]), [(\"Bipendulum Parameterized\", [1.0, 2.0]),  (\"No system\", [1.0, 2.0])]))\n",
    "\n",
    "all_ranges = [(2, 12), (2, 3)]\n",
    "all_dataset_sizes = [1, 2, 5, 10, 20, 50, 100]\n",
    "all_noises = [0.0, 0.1, 0.2, 0.3]\n",
    "\n",
    "all_experiment_settings = list(itertools.product([(2, 12), (2, 3)], [1, 2, 5, 10, 20, 50, 100], [0.0, 0.1, 0.2, 0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpack_experiment_setting(experiment_setting):\n",
    "    return *experiment_setting[0], *experiment_setting[1:]\n",
    "\n",
    "def unpack_model_setting(model_setting):\n",
    "    return model_setting[0], *model_setting[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58054d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results_path = Path.cwd().parent.joinpath(\"results\").joinpath(\"results\")\n",
    "construct_experiment_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_result(f\"{construct_model_name(all_model_settings[0][0], *all_model_settings[0][1])}\", emcd['MLL'],  construct_experiment_path(*all_experiment_settings[0][0], *all_experiment_settings[0][1:], results_path=base_results_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3470b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_result(f\"{construct_model_name(*unpack_model_setting(all_model_settings[0]))}\", emcd['MLL'],  construct_experiment_path(*unpack_experiment_setting(all_experiment_settings[0]), results_path=base_results_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_setting, model_setting in itertools.product(all_experiment_settings, all_model_settings):\n",
    "    try:\n",
    "        model_name = construct_model_name(*unpack_model_setting(model_setting))\n",
    "        experiment_path = construct_experiment_path(*unpack_experiment_setting(experiment_setting), results_path=base_results_path)\n",
    "        result = load_model_result(f\"{model_name}\", emcd['MLL'], experiment_path)\n",
    "        print(f\"Successfully loaded result for {model_setting} in experiment {experiment_setting}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading result for {model_setting} in experiment {experiment_setting}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage3_129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
